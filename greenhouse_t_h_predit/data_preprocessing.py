import pandas as pd
import numpy as np
import os

# ==============================================================================
# ğŸ› ï¸ ìˆ˜ì •ëœ load_and_merge_data í•¨ìˆ˜: ASOS ì»¬ëŸ¼ ì¤‘ë³µ ì˜¤ë¥˜ ìµœì¢… í•´ê²°
# ==============================================================================
def load_and_merge_data(greenhouse_path, asos_weather_path):
    """
    ì˜¨ì‹¤ ë°ì´í„°ì™€ ê³¼ê±° ASOS ê¸°ìƒ ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    """
    print("="*60)
    print("ë°ì´í„° ë¡œë“œ ë° ë³‘í•©")
    print("="*60)
    
    # 1. ì˜¨ì‹¤ ë°ì´í„° ë¡œë“œ (ì´ì „ ìˆ˜ì • ì‚¬í•­ ìœ ì§€)
    print("\n[1] ì˜¨ì‹¤ ì„¼ì„œ ë°ì´í„° ë¡œë“œ")
    if not os.path.exists(greenhouse_path):
        raise FileNotFoundError(f"ì˜¨ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {greenhouse_path}")
    
    delimiter = ';'
    print(f" Â âœ“ êµ¬ë¶„ì: ì„¸ë¯¸ì½œë¡ (;)")
    
    try:
        new_column_names = [
            'Date&Time', 'release_cooling', 'meas_lee_vent_contr', 
            'radiation', 'radiation_sum', 'status_swi_cool', 
            'vent_temp', 'meas_curtain_2', 'inner_temp', 'inner_temp_2', 
            'set_heat_temp', 'set_vent_temp', 'outer_temp', 'heat_temp'
        ]
        
        greenhouse_df = pd.read_csv(
            greenhouse_path, 
            sep=delimiter, 
            skiprows=3, 
            names=new_column_names, 
            encoding='utf-8'
        )
        print(f" Â âœ“ CSV ë¡œë“œ: {greenhouse_df.shape} (skiprows=3, names ì‚¬ìš©)")
        
    except Exception as e:
        print(f" Â âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise 
    
    if 'inner_temp_2' in greenhouse_df.columns:
        greenhouse_df = greenhouse_df.drop('inner_temp_2', axis=1)

    time_col = 'Date&Time'
    try:
        greenhouse_df[time_col] = pd.to_datetime(greenhouse_df[time_col], format='%d-%m-%Y %H:%M:%S')
        print(" Â âœ“ ë‚ ì§œ ë³€í™˜ ì„±ê³µ (DD-MM-YYYY HH:MM:SS)")
    except Exception:
        greenhouse_df[time_col] = pd.to_datetime(greenhouse_df[time_col], dayfirst=True)
        print(" Â âœ“ ë‚ ì§œ ë³€í™˜ ì„±ê³µ (ìë™ ê°ì§€)")

    print(f" Â âœ“ ì˜¨ì‹¤ ì˜¨ë„: 'inner_temp' (ì‚¬ìš©)")
    
    if 'inner_hum' not in greenhouse_df.columns:
        print(f" Â âš ï¸ Â ì˜¨ì‹¤ ìŠµë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        greenhouse_df['inner_hum'] = 70.0
    
    required_cols = ['Date&Time', 'inner_temp', 'inner_hum', 'outer_temp', 
                     'radiation', 'radiation_sum', 'release_cooling', 
                     'meas_lee_vent_contr', 'status_swi_cool', 'vent_temp', 
                     'meas_curtain_2', 'set_heat_temp', 'set_vent_temp', 'heat_temp']
    
    available_cols = [col for col in required_cols if col in greenhouse_df.columns]
    greenhouse_df = greenhouse_df[available_cols]

    numeric_cols = [col for col in available_cols if col not in ['Date&Time']]
    for col in numeric_cols:
        greenhouse_df.loc[:, col] = pd.to_numeric(greenhouse_df[col], errors='coerce')

    print(f"\n Â âœ“ ì˜¨ì‹¤ ë°ì´í„°: {greenhouse_df.shape}")
    
    # 5ë¶„ ë°ì´í„°ë¥¼ 1ì‹œê°„ ë°ì´í„°ë¡œ ë¦¬ìƒ˜í”Œë§
    print(f"\n Â ğŸ”„ ì‹œê°„ ë‹¨ìœ„ë¡œ ë¦¬ìƒ˜í”Œë§ (í‰ê· )...")
    greenhouse_df = greenhouse_df.set_index('Date&Time')
    greenhouse_df = greenhouse_df.resample('1H').mean().reset_index() 
    greenhouse_df = greenhouse_df.dropna(subset=['inner_temp', 'outer_temp'])
    print(f" Â âœ“ ë¦¬ìƒ˜í”Œë§ í›„: {greenhouse_df.shape}")
    
    # ------------------------------------------------------------
    # 2. ASOS ê¸°ìƒ ë°ì´í„° ë¡œë“œ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
    # ------------------------------------------------------------
    print("\n[2] ASOS ê¸°ìƒ ë°ì´í„° ë¡œë“œ (í•™ìŠµìš©)")
    if not os.path.exists(asos_weather_path):
        raise FileNotFoundError(f"âš ï¸ Â ASOS ê¸°ìƒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {asos_weather_path}")

    # **ASOS ë°ì´í„° ë¡œë“œ ì‹œ ì¤‘ë³µëœ 'Date&Time' ì»¬ëŸ¼ì´ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ì»¬ëŸ¼ ì´ë¦„ì„ ì¡°ì •í•˜ë©° ë¡œë“œ**
    asos_df = pd.read_csv(asos_weather_path)
    print(f" Â ì›ë³¸ ì»¬ëŸ¼: {list(asos_df.columns)}")
    
    # === ì¤‘ë³µ Date&Time ì»¬ëŸ¼ ì²˜ë¦¬ ë¡œì§ ê°•í™” ===
    
    # 1. ì¤‘ë³µëœ 'Date&Time' ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
    col_names = asos_df.columns.tolist()
    duplicate_indices = [i for i, x in enumerate(col_names) if x == 'Date&Time']

    if len(duplicate_indices) > 1:
        print(f" Â âš ï¸ Â ASOS ë°ì´í„°ì— 'Date&Time' ì¤‘ë³µ ì»¬ëŸ¼ {len(duplicate_indices)}ê°œ ë°œê²¬. ì²« ë²ˆì§¸ ì»¬ëŸ¼ë§Œ ë‚¨ê¹ë‹ˆë‹¤.")
        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ë§Œ Trueë¡œ, ë‚˜ë¨¸ì§€ëŠ” Falseì¸ boolean ë§ˆìŠ¤í¬ ìƒì„±
        keep_mask = [True] * len(col_names)
        for i in duplicate_indices[1:]:
            keep_mask[i] = False
        
        # ì¤‘ë³µ ì»¬ëŸ¼ì„ ì œê±°í•œ ìƒˆ DataFrame ìƒì„±
        asos_df = asos_df.iloc[:, keep_mask]
        
    # 2. ìµœì¢… ì‹œê°„ ì»¬ëŸ¼ ì´ë¦„ í™•ì •
    asos_time_col = None
    time_candidates = ['Date&Time', 'date', 'datetime', 'tm', 'time', 'timestamp']
    for col in time_candidates:
        if col in asos_df.columns:
            asos_time_col = col
            break
            
    if asos_time_col is None:
        raise ValueError("ASOS ë°ì´í„°ì—ì„œ ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print(f" Â âœ“ ì‹œê°„ ì»¬ëŸ¼ ë°œê²¬: '{asos_time_col}'")
    
    # 3. ì‹œê°„ ì»¬ëŸ¼ì„ 'Date&Time'ìœ¼ë¡œ í‘œì¤€í™” ë° ë³€í™˜
    if asos_time_col != 'Date&Time':
        asos_df = asos_df.rename(columns={asos_time_col: 'Date&Time'})
        
    asos_df['Date&Time'] = pd.to_datetime(asos_df['Date&Time']) 
    print(" Â âœ“ 'Date&Time' ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ.")

    # 4. ASOS ë°ì´í„° ì»¬ëŸ¼ í‘œì¤€í™” (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    asos_column_mapping = {
        'ta': 'outer_temp', 'temp': 'outer_temp', 'temperature': 'outer_temp',
        'hm': 'outer_hum', 'rh': 'outer_hum', 'humidity': 'outer_hum',
        'ws': 'wind_speed', 'wind': 'wind_speed',
        'wd': 'wind_dir', 'wind_direction': 'wind_dir',
        'rn': 'rainfall', 'precipitation': 'rainfall', 'rain': 'rainfall',
        'si': 'solar_rad', 'solar': 'solar_rad', 'radiation': 'solar_rad',
        'icsr': 'solar_rad', 'ps': 'pressure',
    }
    
    for old_name, new_name in asos_column_mapping.items():
        if old_name in asos_df.columns:
            asos_df = asos_df.rename(columns={old_name: new_name})
            
    # ì˜¨ì‹¤ ë°ì´í„°ì˜ outer_tempì™€ radiationì„ ASOS ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ì§€ ì•Šê¸° ìœ„í•´ ë³‘í•© ì»¬ëŸ¼ ì¡°ì •
    asos_merge_cols = [col for col in ['Date&Time', 'outer_hum', 'wind_speed', 'wind_dir', 
                                       'rainfall', 'solar_rad', 'pressure'] if col in asos_df.columns]
    
    asos_df = asos_df[asos_merge_cols].drop_duplicates(subset=['Date&Time'], keep='first')
    
    print(f" Â âœ“ ASOS ë°ì´í„°: {asos_df.shape}")
    print(f" Â âœ“ ASOS ì»¬ëŸ¼ í‘œì¤€í™” ì™„ë£Œ")

    # 3. ë°ì´í„° ë³‘í•©
    print("\n[3] ì˜¨ì‹¤ ë°ì´í„° + ASOS ê¸°ìƒ ë°ì´í„° ë³‘í•©")
    
    greenhouse_df = greenhouse_df.sort_values('Date&Time')
    asos_df = asos_df.sort_values('Date&Time')
    
    merged_df = pd.merge_asof(
        greenhouse_df,
        asos_df,
        on='Date&Time',
        direction='nearest',
        tolerance=pd.Timedelta('1H')
    )
    
    # ê¸°ìƒ ë°ì´í„° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ASOSì—ì„œ ê°€ì ¸ì˜¨ ì»¬ëŸ¼ë§Œ ì²˜ë¦¬)
    weather_cols_from_asos = [col for col in asos_merge_cols if col != 'Date&Time']
    
    for col in weather_cols_from_asos:
        if col in merged_df.columns:
            merged_df[col] = merged_df[col].fillna(method='ffill').fillna(method='bfill')
            if merged_df[col].isnull().sum() > 0:
                merged_df[col] = merged_df[col].fillna(merged_df[col].mean())
    
    print(f" Â âœ“ ë³‘í•© ì™„ë£Œ: {merged_df.shape}")
    
    final_cols_order = ['Date&Time', 'inner_temp', 'inner_hum', 'outer_temp', 
                        'radiation', 'radiation_sum', 'release_cooling', 
                        'meas_lee_vent_contr', 'status_swi_cool', 'vent_temp', 
                        'meas_curtain_2', 'set_heat_temp', 'set_vent_temp', 'heat_temp'] + weather_cols_from_asos
    
    final_cols_order = list(dict.fromkeys(final_cols_order))
    final_cols_order = [col for col in final_cols_order if col in merged_df.columns]
    
    return merged_df[final_cols_order]

# ==============================================================================
# ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ (ë³€ê²½ ì—†ìŒ)
# ==============================================================================

def add_time_features(df):
    """ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ì¶”ê°€"""
    print("\n[4] ì‹œê°„ íŠ¹ì„± ì¶”ê°€")
    
    df = df.copy()
    
    df['hour'] = df['Date&Time'].dt.hour
    df['day'] = df['Date&Time'].dt.day
    df['month'] = df['Date&Time'].dt.month
    df['dayofweek'] = df['Date&Time'].dt.dayofweek
    
    # ì£¼ê¸°ì  ì‹œê°„ íŠ¹ì„± (sin/cos ì¸ì½”ë”©)
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)
    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)
    
    # ê³„ì ˆ (0: ê²¨ìš¸, 1: ë´„, 2: ì—¬ë¦„, 3: ê°€ì„)
    df['season'] = df['month'].apply(lambda x: 
        0 if x in [12, 1, 2] else
        1 if x in [3, 4, 5] else
        2 if x in [6, 7, 8] else 3
    )
    
    # ì£¼ë§ ì—¬ë¶€
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
    
    print(f" Â âœ“ ì‹œê°„ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ: 12ê°œ íŠ¹ì„±")
    
    return df


def handle_missing_values(df):
    """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    print("\n[5] ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
    
    missing = df.isnull().sum()
    if missing.sum() > 0:
        print(f" Â âš ï¸ Â ê²°ì¸¡ì¹˜ ë°œê²¬:")
        for col, count in missing[missing > 0].items():
            print(f" Â  Â - {col}: {count}ê°œ ({count/len(df)*100:.2f}%)")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            df[col] = df[col].fillna(method='ffill').fillna(method='bfill')
            if df[col].isnull().sum() > 0:
                mean_val = df[col].mean()
                if pd.isna(mean_val):
                    df[col] = df[col].fillna(0)
                else:
                    df[col] = df[col].fillna(mean_val)
        
        print(f" Â âœ“ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
    else:
        print(f" Â âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ")
    
    return df


def handle_outliers(df, columns=None, method='iqr', threshold=3):
    """ì´ìƒì¹˜ ì²˜ë¦¬"""
    print("\n[6] ì´ìƒì¹˜ ì²˜ë¦¬")
    
    df = df.copy()
    
    if columns is None:
        columns = df.select_dtypes(include=[np.number]).columns
        exclude_cols = ['hour', 'day', 'month', 'dayofweek', 'season', 'is_weekend',
                        'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos']
        columns = [col for col in columns if col not in exclude_cols]
    
    outlier_count = 0
    
    for col in columns:
        if col not in df.columns:
            continue
        
        if method == 'iqr':
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - threshold * IQR
            upper_bound = Q3 + threshold * IQR
            
            outliers = (df[col] < lower_bound) | (df[col] > upper_bound)
            
        elif method == 'zscore':
            mean = df[col].mean()
            std = df[col].std()
            
            if std == 0:
                continue
            
            z_scores = np.abs((df[col] - mean) / std)
            outliers = z_scores > threshold
        
        if outliers.sum() > 0:
            outlier_count += outliers.sum()
            median_value = df[col].median()
            df.loc[outliers, col] = median_value
    
    print(f" Â âœ“ ì´ìƒì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {outlier_count}ê°œ ê°’ ìˆ˜ì •")
    
    return df


def create_lag_features(df, target_cols=['inner_temp', 'inner_hum'], lags=[1, 3, 6]):
    """ì§€ì—°(lag) íŠ¹ì„± ìƒì„±"""
    print("\n[7] ì§€ì—°(Lag) íŠ¹ì„± ìƒì„±")
    print(f" Â ëŒ€ìƒ ì»¬ëŸ¼: {target_cols}")
    print(f" Â Lag ì‹œê°„: {lags}ì‹œê°„")
    
    df = df.copy()
    lag_cols_created = []
    
    for col in target_cols:
        if col not in df.columns:
            print(f" Â âš ï¸ Â ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {col}")
            continue
        
        for lag in lags:
            lag_col_name = f'{col}_lag_{lag}'
            df[lag_col_name] = df[col].shift(lag)
            lag_cols_created.append(lag_col_name)
            print(f" Â  Â âœ“ {lag_col_name} ìƒì„±")
    
    print(f" Â âœ“ ìƒì„±ëœ lag íŠ¹ì„±: {len(lag_cols_created)}ê°œ")
    
    # Lagë¡œ ì¸í•œ ê²°ì¸¡ì¹˜ ì œê±°
    initial_len = len(df)
    df = df.dropna()
    removed = initial_len - len(df)
    
    if removed > 0:
        print(f" Â âœ“ Lag ê²°ì¸¡ì¹˜ ì œê±°: {removed}ê°œ í–‰")
    
    return df


def preprocess_data(greenhouse_path, asos_weather_path, output_path, 
                    add_lags=True, lag_hours=[1, 3, 6],
                    handle_outlier=True, outlier_method='iqr'):
    """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    print("\n" + "="*60)
    print("ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*60)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    df = load_and_merge_data(greenhouse_path, asos_weather_path)
    
    # 2. ì‹œê°„ íŠ¹ì„± ì¶”ê°€
    df = add_time_features(df)
    
    # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = handle_missing_values(df)
    
    # 4. ì´ìƒì¹˜ ì²˜ë¦¬
    if handle_outlier:
        df = handle_outliers(df, method=outlier_method, threshold=3)
    
    # 5. Lag íŠ¹ì„± ìƒì„±
    if add_lags:
        df = create_lag_features(df, target_cols=['inner_temp', 'inner_hum'], lags=lag_hours)
    
    # 6. ì •ë ¬ ë° ì¸ë±ìŠ¤ ì¬ì„¤ì •
    df = df.sort_values('Date&Time').reset_index(drop=True)
    
    # 7. ìµœì¢… ê²°ê³¼
    print("\n" + "="*60)
    print("[8] ì „ì²˜ë¦¬ ì™„ë£Œ")
    print("="*60)
    print(f" Â âœ“ ìµœì¢… ë°ì´í„°: {df.shape}")
    print(f" Â âœ“ ê¸°ê°„: {df['Date&Time'].min()} ~ {df['Date&Time'].max()}")
    print(f" Â âœ“ ì´ ì‹œê°„: {len(df)}ì‹œê°„")
    print(f"\n Â âœ“ ì»¬ëŸ¼ ëª©ë¡ ({len(df.columns)}ê°œ):")
    
    # ì»¬ëŸ¼ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
    time_cols = [col for col in df.columns if 'Date&Time' in col]
    inner_cols = [col for col in df.columns if 'inner' in col]
    outer_cols = [col for col in df.columns if 'outer' in col or col in ['wind_speed', 'wind_dir', 'rainfall', 'solar_rad', 'pressure']]
    time_feature_cols = [col for col in df.columns if any(x in col for x in ['hour', 'day', 'month', 'season', 'weekend', 'sin', 'cos'])]
    
    print(f" Â  Â - ì‹œê°„: {time_cols}")
    print(f" Â  Â - ì˜¨ì‹¤: {inner_cols}")
    print(f" Â  Â - ê¸°ìƒ: {outer_cols}")
    print(f" Â  Â - ì‹œê°„íŠ¹ì„±: {time_feature_cols}")
    
    # 8. ì €ì¥
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ì €ì¥: {output_path}")
    
    # 9. í†µê³„
    print(f"\nğŸ“Š ì£¼ìš” í†µê³„:")
    stats_cols = [col for col in ['inner_temp', 'inner_hum', 'outer_temp', 'outer_hum'] 
                  if col in df.columns]
    if stats_cols:
        print(df[stats_cols].describe())
    
    return df


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("="*60)
    print("ğŸŒ± ì˜¨ì‹¤ ë¯¸ê¸°í›„ ë°ì´í„° ì „ì²˜ë¦¬")
    print("="*60)
    
    GREENHOUSE_PATH = 'input/greenhouse_inner_8_1year.csv'
    ASOS_WEATHER_PATH = 'input/asos_weather.csv'
    OUTPUT_PATH = 'output/preprocessed_data.csv'
    
    if not os.path.exists(GREENHOUSE_PATH):
        print(f"\nâŒ íŒŒì¼ ì—†ìŒ: {GREENHOUSE_PATH}")
        return None
    
    if not os.path.exists(ASOS_WEATHER_PATH):
        print(f"\nâŒ íŒŒì¼ ì—†ìŒ: {ASOS_WEATHER_PATH}")
        print("ë¨¼ì € 'python asos_download.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    try:
        df = preprocess_data(
            greenhouse_path=GREENHOUSE_PATH,
            asos_weather_path=ASOS_WEATHER_PATH,
            output_path=OUTPUT_PATH,
            add_lags=True,
            lag_hours=[1, 3, 6],  # 1ì‹œê°„, 3ì‹œê°„, 6ì‹œê°„ ì „ ë°ì´í„°
            handle_outlier=True,
            outlier_method='iqr'
        )
        
        print("\n" + "="*60)
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print("="*60)
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: python model_training.py")
        
        return df
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()