import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import os
import sys
import requests
import subprocess 

from google import genai 
from future_prediction import GreenhouseFuturePredictor

# --- [Gemini ë° Telegram ì„¤ì •] ---
# ğŸ”‘ Gemini ì„¤ì •
GEMINI_API_KEY = "" # ì‚¬ìš©ì í‚¤ ìœ ì§€

# ğŸ“¢ Telegram ì„¤ì •
TELEGRAM_BOT_TOKEN = "8544768473:AAGlHKkR_r7-IjxoUqBrxcJd3aD6vRPSmvQ"
TELEGRAM_CHAT_ID = "7078646539"

# ì˜¨ì‹¤ í™˜ê²½ ë° ì„ê³„ì¹˜ ì„¤ì • (ìˆ˜ì •ë¨)
CROP_NAME = "ë°©ìš¸í† ë§ˆí† "
TEMP_THRESHOLD_HIGH = 25.0
TEMP_THRESHOLD_LOW = 20.0  # 20ë„ ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ì•ŒëŒ
HUMIDITY_THRESHOLD_LOW = 50.0

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    gemini_client = genai.Client(api_key=GEMINI_API_KEY)
except Exception as e:
    gemini_client = None

# --- [í˜ì´ì§€ ì„¤ì •] ---
st.set_page_config(page_title="ì˜¨ì‹¤ ë¯¸ê¸°í›„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ", page_icon="ğŸŒ±", layout="wide")

st.markdown("""
<style>
    .main-header { font-size: 2.5rem; font-weight: bold; color: #2E7D32; text-align: center; margin-bottom: 2rem; }
    .metric-card { background-color: #f0f2f6; padding: 1rem; border-radius: 0.5rem; border-left: 4px solid #2E7D32; }
</style>
""", unsafe_allow_html=True)

if 'predictor' not in st.session_state: st.session_state.predictor = None
if 'predictions' not in st.session_state: st.session_state.predictions = None

# --- [í•¨ìˆ˜ ì •ì˜] ---
def get_gemini_advice(pred_temp, pred_humid, crop_name):
    if not gemini_client: return "API í‚¤ í™•ì¸ í•„ìš”"
    prompt = f"ë‹¹ì‹ ì€ {crop_name} ì¬ë°° ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì˜¨ì‹¤ ì˜¨ë„ê°€ {pred_temp:.1f}Â°C, ìŠµë„ê°€ {pred_humid:.1f}%ë¡œ ìœ„í—˜ ìˆ˜ì¤€ì´ ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì·¨í•´ì•¼ í•  ì¡°ì¹˜ì‚¬í•­ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
    try:
        response = gemini_client.models.generate_content(model='gemini-2.5-flash', contents=prompt)
        return response.text
    except Exception as e: return f"Gemini ì˜¤ë¥˜: {e}"

def send_telegram_alert(msg):
    if not TELEGRAM_BOT_TOKEN: return "í…”ë ˆê·¸ë¨ ì„¤ì • í•„ìš”"
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        requests.post(url, data={'chat_id': TELEGRAM_CHAT_ID, 'text': msg, 'parse_mode': 'Markdown'})
        return "âœ… ì•ŒëŒ ë°œì†¡ ì„±ê³µ"
    except Exception as e: return f"âŒ ë°œì†¡ ì‹¤íŒ¨: {e}"

def check_and_get_alert_data(df):
    """
    [ìˆ˜ì •ë¨] 6ì‹œê°„ ì˜ˆì¸¡ ë°ì´í„° ì¤‘ 'ìµœì €/ìµœê³ ' ê°’ì„ ê²€ì‚¬í•˜ì—¬ ì•ŒëŒ ë°œìƒ ì—¬ë¶€ ê²°ì •
    """
    if df is None or df.empty: return None
    
    # ì „ì²´ ì˜ˆì¸¡ ê¸°ê°„ í†µê³„
    min_temp = df['Predicted_inner_temp'].min()
    max_temp = df['Predicted_inner_temp'].max()
    min_hum = df['Predicted_inner_hum'].min()
    
    # ì•ŒëŒ ì¡°ê±´ í™•ì¸
    reasons = []
    alert_temp = min_temp # ê¸°ë³¸ê°’
    
    if max_temp >= TEMP_THRESHOLD_HIGH:
        reasons.append(f"âš ï¸ ê³ ì˜¨ ê²½ë³´ (ìµœê³  {max_temp:.1f}Â°C)")
        alert_temp = max_temp
    
    if min_temp <= TEMP_THRESHOLD_LOW:
        reasons.append(f"âš ï¸ ì €ì˜¨ ê²½ë³´ (ìµœì € {min_temp:.1f}Â°C)")
        alert_temp = min_temp
        
    if min_hum <= HUMIDITY_THRESHOLD_LOW:
        reasons.append(f"âš ï¸ ì €ìŠµ ê²½ë³´ (ìµœì € {min_hum:.1f}%)")
    
    if reasons:
        # ìœ„í—˜ì´ ê°ì§€ëœ ì‹œê°„ëŒ€ ì°¾ê¸° (ê°€ì¥ ë¨¼ì € ìœ„í—˜í•´ì§€ëŠ” ì‹œê°„)
        risk_row = df[
            (df['Predicted_inner_temp'] <= TEMP_THRESHOLD_LOW) | 
            (df['Predicted_inner_temp'] >= TEMP_THRESHOLD_HIGH) |
            (df['Predicted_inner_hum'] <= HUMIDITY_THRESHOLD_LOW)
        ].iloc[0]
        
        return {
            'temp': risk_row['Predicted_inner_temp'],
            'humid': risk_row['Predicted_inner_hum'],
            'time': risk_row['Date&Time'].strftime('%H:%M'),
            'reason': ", ".join(reasons)
        }
    return None

def load_predictor():
    try:
        p = GreenhouseFuturePredictor('output/best_model.pth', 'output/cache')
        p.load_model_and_scalers()
        return p
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# --- [ì°¨íŠ¸ í•¨ìˆ˜] ---
def create_combined_chart(df):
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df['Date&Time'], y=df['Predicted_inner_temp'], name='ì˜¨ë„(Â°C)', line=dict(color='#FF6B6B', width=3)))
    fig.add_trace(go.Scatter(x=df['Date&Time'], y=df['Predicted_inner_hum'], name='ìŠµë„(%)', yaxis='y2', line=dict(color='#95E1D3', width=3)))
    
    # ì„ê³„ì¹˜ ë¼ì¸ ì¶”ê°€ (ì‹œê°ì  í™•ì¸ìš©)
    fig.add_hline(y=TEMP_THRESHOLD_LOW, line_dash="dot", line_color="blue", annotation_text="ì €ì˜¨ ì„ê³„ì¹˜")
    fig.add_hline(y=TEMP_THRESHOLD_HIGH, line_dash="dot", line_color="red", annotation_text="ê³ ì˜¨ ì„ê³„ì¹˜")
    
    fig.update_layout(
        title='ì˜¨ì‹¤ ì˜¨ìŠµë„ ì˜ˆì¸¡ (6ì‹œê°„)', xaxis_title='ì‹œê°„',
        yaxis=dict(title='ì˜¨ë„'), yaxis2=dict(title='ìŠµë„', overlaying='y', side='right'),
        hovermode='x unified', height=400, template='plotly_white'
    )
    return fig

# --- [ë©”ì¸ í•¨ìˆ˜] ---
def main():
    st.markdown('<div class="main-header">ğŸŒ± ì˜¨ì‹¤ ë¯¸ê¸°í›„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)
    
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        forecast_path = st.text_input("ê¸°ìƒì²­ ì˜ˆë³´ ë°ì´í„°", "input/weather_forecast.csv")
        preprocessed_path = st.text_input("ì „ì²˜ë¦¬ ë°ì´í„°", "output/preprocessed_data.csv")
        hours_to_predict = st.slider("ì˜ˆì¸¡ ì‹œê°„", 1, 24, 6)
        predict_button = st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary", use_container_width=True)

    # ------------------------------------------------------------------
    # 1. ì˜ˆì¸¡ ì‹¤í–‰ ë¡œì§
    # ------------------------------------------------------------------
    if predict_button:
        # A. ë‹¨ê¸° ì˜ˆë³´ ë‹¤ìš´ë¡œë“œ
        st.info("ğŸ“¡ ê¸°ìƒì²­ ì˜ˆë³´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
        SCRIPT = 'short_term_forecast_download.py'
        
        if os.path.exists(SCRIPT):
            try:
                env = os.environ.copy()
                env["PYTHONIOENCODING"] = "utf-8"
                res = subprocess.run([sys.executable, SCRIPT], capture_output=True, text=True, encoding='utf-8', errors='replace', env=env, check=False)
                
                if res.returncode == 0:
                    st.success("âœ… ì˜ˆë³´ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                else:
                    st.error("âŒ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜")
                    st.error(res.stderr)
            except Exception as e:
                st.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        else:
            st.warning(f"âš ï¸ {SCRIPT} ì—†ìŒ")

        # B. íŒŒì¼ í™•ì¸
        if not os.path.exists(forecast_path):
            st.error(f"âŒ íŒŒì¼ ì—†ìŒ: {forecast_path}")
            return

        # C. ëª¨ë¸ ì˜ˆì¸¡
        with st.spinner("ğŸ”® ë¯¸ë˜ í™˜ê²½ ì˜ˆì¸¡ ì¤‘..."):
            if st.session_state.predictor is None:
                st.session_state.predictor = load_predictor()
            
            if st.session_state.predictor:
                try:
                    preds = st.session_state.predictor.predict(
                        forecast_path=forecast_path,
                        preprocessed_path=preprocessed_path,
                        target_date=None, 
                        hours_to_predict=hours_to_predict
                    )
                    st.session_state.predictions = preds
                    
                    if preds is not None and not preds.empty:
                        st.success(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ({len(preds)}ê°œ ë°ì´í„°)")
                    else:
                        st.error("âŒ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ")
                except Exception as e:
                    st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")

        # D. ì•ŒëŒ ë¡œì§ (ìˆ˜ì •ë¨)
        alert = check_and_get_alert_data(st.session_state.predictions)
        if alert:
            st.warning(f"ğŸš¨ **ìœ„í—˜ ê°ì§€!** {alert['time']}ê²½ {alert['reason']}")
            
            with st.spinner("ğŸ¤– Gemini ì¡°ì–¸ ìƒì„± ì¤‘..."):
                advice = get_gemini_advice(alert['temp'], alert['humid'], CROP_NAME)
            
            msg = f"""
ğŸš¨ *{CROP_NAME} ê¸´ê¸‰ ì•ŒëŒ* ğŸš¨

ğŸ›‘ *ìœ„í—˜ ê°ì§€*: {alert['reason']}
â° *ë°œìƒ ì˜ˆìƒ*: {alert['time']}
ğŸŒ¡ï¸ *ì˜ˆì¸¡ ì˜¨ë„*: {alert['temp']:.1f}Â°C
ğŸ’§ *ì˜ˆì¸¡ ìŠµë„*: {alert['humid']:.1f}%

ğŸ¤– *Gemini ì¡°ì–¸*:
{advice}
"""
            st.markdown(f"**Telegram ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°:**\n```\n{msg}\n```")
            status = send_telegram_alert(msg)
            st.info(f"ì•ŒëŒ ì „ì†¡ ìƒíƒœ: {status}")
        else:
            st.success("âœ… í–¥í›„ 6ì‹œê°„ ë™ì•ˆ ìœ„í—˜ êµ¬ê°„ ì—†ìŒ")

    # ------------------------------------------------------------------
    # 2. ê²°ê³¼ ì‹œê°í™”
    # ------------------------------------------------------------------
    df = st.session_state.predictions

    if df is not None and not df.empty:
        st.divider()
        st.subheader(f"ğŸ“Š {hours_to_predict}ì‹œê°„ ì˜ˆì¸¡ ê²°ê³¼")
        
        c1, c2, c3 = st.columns(3)
        c1.metric("ìµœì € ì˜¨ë„", f"{df['Predicted_inner_temp'].min():.1f}Â°C", delta_color="inverse")
        c2.metric("ìµœê³  ì˜¨ë„", f"{df['Predicted_inner_temp'].max():.1f}Â°C")
        c3.metric("í‰ê·  ìŠµë„", f"{df['Predicted_inner_hum'].mean():.1f}%")

        st.plotly_chart(create_combined_chart(df), use_container_width=True)
        
        with st.expander("ğŸ” ë°ì´í„° ìƒì„¸ ë³´ê¸°"):
            st.dataframe(df)

if __name__ == "__main__":

    main()
