import requests
import pandas as pd
import os
import time
from datetime import datetime, timedelta
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def fetch_weather_data(start_date, end_date, stn_ids, service_key):
    """
    ASOS ê¸°ìƒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    
    Args:
        start_date (str): ì‹œì‘ì¼ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œì¼ (YYYY-MM-DD)
        stn_ids (str): ê¸°ìƒëŒ€ ì½”ë“œ
        service_key (str): API ì¸ì¦í‚¤
    Returns:
        pd.DataFrame: ê¸°ìƒ ë°ì´í„°
    """
    startDt = start_date.replace('-', '')
    endDt = end_date.replace('-', '')

    url = "https://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList"
    
    all_data = []
    page_no = 1
    total_pages = 1
    max_retries = 3

    print(f"\nğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘: {start_date} ~ {end_date}")
    
    while page_no <= total_pages:
        params = {
            'serviceKey': service_key,
            'numOfRows': '999',  # í•œ í˜ì´ì§€ë‹¹ ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜
            'pageNo': str(page_no),
            'dataType': 'JSON',
            'dataCd': 'ASOS',
            'dateCd': 'HR',  # ì‹œê°„ë³„ ë°ì´í„°
            'startDt': startDt,
            'startHh': '00',
            'endDt': endDt,
            'endHh': '23',
            'stnIds': stn_ids
        }

        retry_count = 0
        success = False
        
        while retry_count < max_retries and not success:
            try:
                print(f"  ğŸ“„ í˜ì´ì§€ {page_no}/{total_pages} ë‹¤ìš´ë¡œë“œ ì¤‘...", end='')
                if retry_count > 0:
                    print(f" [ì¬ì‹œë„ {retry_count}/{max_retries}]", end='')
                print()
                
                response = requests.get(
                    url, 
                    params=params, 
                    verify=False, 
                    timeout=(10, 60),
                    headers={'Connection': 'close'}
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # ì‘ë‹µ í™•ì¸
                    if 'response' not in data:
                        print(f"    âš ï¸ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                        return None
                    
                    # ì—ëŸ¬ ì½”ë“œ í™•ì¸
                    if 'header' in data['response']:
                        result_code = data['response']['header'].get('resultCode', '00')
                        result_msg = data['response']['header'].get('resultMsg', 'SUCCESS')
                        
                        if result_code != '00':
                            print(f"    âŒ API ì˜¤ë¥˜: [{result_code}] {result_msg}")
                            if result_code == '03':
                                print(f"    â†’ í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            return None
                    
                    # ë°ì´í„° í™•ì¸
                    if 'body' not in data['response'] or 'items' not in data['response']['body']:
                        print(f"    âš ï¸ ë°ì´í„° ì—†ìŒ")
                        return None

                    items = data['response']['body']['items']['item']
                    
                    # ë‹¨ì¼ í•­ëª©ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if isinstance(items, dict):
                        items = [items]
                    
                    df = pd.json_normalize(items)
                    all_data.append(df)
                    
                    print(f"    âœ“ {len(df)} ë ˆì½”ë“œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

                    # ì²« í˜ì´ì§€ì—ì„œ ì „ì²´ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
                    if page_no == 1:
                        total_count = data['response']['body']['totalCount']
                        num_of_rows = int(params['numOfRows'])
                        total_pages = (total_count // num_of_rows) + (1 if total_count % num_of_rows > 0 else 0)
                        print(f"    ğŸ“Š ì´ {total_count} ë ˆì½”ë“œ, {total_pages} í˜ì´ì§€")

                    page_no += 1
                    success = True
                    time.sleep(0.5)  # API í˜¸ì¶œ ê°„ê²©
                    
                elif response.status_code == 500:
                    print(f"    âš ï¸ ì„œë²„ ì˜¤ë¥˜ (500), ì¬ì‹œë„...")
                    retry_count += 1
                    time.sleep(3)
                else:
                    print(f"    âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
                    return None
                    
            except requests.exceptions.Timeout:
                retry_count += 1
                print(f"    â±ï¸ íƒ€ì„ì•„ì›ƒ ë°œìƒ, {3 * retry_count}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(3 * retry_count)
                
            except requests.exceptions.RequestException as e:
                print(f"    âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
                retry_count += 1
                time.sleep(2)
                
            except Exception as e:
                print(f"    âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                return None
        
        if not success:
            print(f"    âŒ {max_retries}ë²ˆ ì¬ì‹œë„ ì‹¤íŒ¨")
            return None

    if all_data:
        final_df = pd.concat(all_data, ignore_index=True)
        print(f"\nâœ… ì´ {len(final_df)} ë ˆì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ")
        return final_df
    else:
        return None


def process_asos_data(df):
    """
    ASOS ë°ì´í„° ì „ì²˜ë¦¬
    
    Args:
        df (pd.DataFrame): ì›ë³¸ ASOS ë°ì´í„°
    Returns:
        pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°
    """
    print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    
    df = df.copy()
    
    # ê¸°ì¡´ ì»¬ëŸ¼ í™•ì¸
    print(f"  ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)}")
    
    # ì»¬ëŸ¼ ë§¤í•‘ (ASOS ì›ë³¸ â†’ í‘œì¤€ëª…)
    column_mapping = {
        'tm': 'datetime_temp',   # ì„ì‹œë¡œ ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©
        'ta': 'outer_temp',      # ê¸°ì˜¨(â„ƒ)
        'hm': 'outer_hum',       # ìŠµë„(%)
        'ws': 'wind_speed',      # í’ì†(m/s)
        'wd': 'wind_dir',        # í’í–¥(deg)
        'rn': 'rainfall',        # ê°•ìˆ˜ëŸ‰(mm)
        'icsr': 'solar_rad',     # ì¼ì‚¬(MJ/m2)
        'ps': 'pressure'         # í˜„ì§€ê¸°ì••(hPa)
    }
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì´ë¦„ ë³€ê²½
    cols_to_rename = {}
    for old_col, new_col in column_mapping.items():
        if old_col in df.columns:
            cols_to_rename[old_col] = new_col
    
    df = df.rename(columns=cols_to_rename)
    
    # datetime_tempë¥¼ Date&Timeìœ¼ë¡œ ë³€í™˜
    if 'datetime_temp' in df.columns:
        df['Date&Time'] = pd.to_datetime(df['datetime_temp'], format='%Y-%m-%d %H:%M')
        df = df.drop('datetime_temp', axis=1)
    else:
        print(f"  âš ï¸ ì‹œê°„ ì»¬ëŸ¼(tm)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    cols_to_keep = ['Date&Time']
    for col in ['outer_temp', 'outer_hum', 'wind_speed', 'wind_dir', 
                'rainfall', 'solar_rad', 'pressure']:
        if col in df.columns:
            cols_to_keep.append(col)
    
    df = df[cols_to_keep]
    
    # ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    numeric_cols = [col for col in df.columns if col != 'Date&Time']
    for col in numeric_cols:
        # ìˆ«ìë¡œ ë³€í™˜
        df[col] = pd.to_numeric(df[col], errors='coerce')
        # -99 ê°™ì€ ê²°ì¸¡ì¹˜ í‘œì‹œë¥¼ NaNìœ¼ë¡œ
        df.loc[df[col] < -90, col] = None
    
    # ì •ë ¬
    df = df.sort_values('Date&Time').reset_index(drop=True)
    
    # ì¤‘ë³µ ì œê±°
    df = df.drop_duplicates(subset=['Date&Time'], keep='first')
    
    print(f"  âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ")
    print(f"  âœ“ ì»¬ëŸ¼: {list(df.columns)}")
    print(f"  âœ“ ê¸°ê°„: {df['Date&Time'].min()} ~ {df['Date&Time'].max()}")
    print(f"  âœ“ ë ˆì½”ë“œ ìˆ˜: {len(df)}")
    
    return df


def test_api_connection(service_key, stn_ids):
    """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    test_url = "https://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList"
    test_params = {
        'serviceKey': service_key,
        'numOfRows': '1',
        'pageNo': '1',
        'dataType': 'JSON',
        'dataCd': 'ASOS',
        'dateCd': 'HR',
        'startDt': '20250416',
        'startHh': '00',
        'endDt': '20250416',
        'endHh': '01',
        'stnIds': stn_ids
    }
    
    try:
        response = requests.get(test_url, params=test_params, verify=False, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            if 'response' in data and 'header' in data['response']:
                result_code = data['response']['header'].get('resultCode', '00')
                result_msg = data['response']['header'].get('resultMsg', 'SUCCESS')
                
                if result_code == '00':
                    print("  âœ… API ì—°ê²° ì„±ê³µ!")
                    return True
                else:
                    print(f"  âš ï¸ API ì˜¤ë¥˜: [{result_code}] {result_msg}")
                    print("\n  ê°€ëŠ¥í•œ ì›ì¸:")
                    print("    1. API í‚¤ê°€ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
                    print("    2. ì¼ì¼ íŠ¸ë˜í”½ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤")
                    print("    3. í•´ë‹¹ ë‚ ì§œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    return False
        else:
            print(f"  âš ï¸ HTTP ì˜¤ë¥˜: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("\n  ëŒ€ì²´ ë°©ë²•:")
        print("    1. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
        print("    2. VPNì„ ì‚¬ìš© ì¤‘ì´ë¼ë©´ ë¹„í™œì„±í™”í•˜ì„¸ìš”")
        print("    3. ë°©í™”ë²½ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”")
        return False


def download_asos_data_by_period(start_date, end_date, stn_ids, service_key, days_per_fetch=30):
    """
    ê¸°ê°„ì„ ë‚˜ëˆ„ì–´ ASOS ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    
    Args:
        start_date (str): ì‹œì‘ì¼
        end_date (str): ì¢…ë£Œì¼
        stn_ids (str): ê¸°ìƒëŒ€ ì½”ë“œ
        service_key (str): API ì¸ì¦í‚¤
        days_per_fetch (int): í•œ ë²ˆì— ê°€ì ¸ì˜¬ ì¼ìˆ˜
    Returns:
        pd.DataFrame: í†µí•© ë°ì´í„°
    """
    start_date_obj = datetime.strptime(start_date, '%Y-%m-%d')
    end_date_obj = datetime.strptime(end_date, '%Y-%m-%d')
    
    all_data = []
    current_date = start_date_obj
    
    while current_date <= end_date_obj:
        fetch_end_date = min(current_date + timedelta(days=days_per_fetch-1), end_date_obj)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“… ê¸°ê°„: {current_date.strftime('%Y-%m-%d')} ~ {fetch_end_date.strftime('%Y-%m-%d')}")
        print(f"{'='*60}")
        
        try:
            df = fetch_weather_data(
                current_date.strftime('%Y-%m-%d'),
                fetch_end_date.strftime('%Y-%m-%d'),
                stn_ids,
                service_key
            )
            
            if df is not None and len(df) > 0:
                all_data.append(df)
                print(f"  âœ… {len(df)} ë ˆì½”ë“œ ìˆ˜ì§‘")
            else:
                print(f"  âš ï¸ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        current_date = fetch_end_date + timedelta(days=1)
        time.sleep(1)  # API í˜¸ì¶œ ê°„ê²©
    
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        # tm ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (Date&Timeìœ¼ë¡œ ë³€í™˜ ì „)
        if 'tm' in combined_df.columns:
            combined_df = combined_df.drop_duplicates(subset=['tm'], keep='first')
        return combined_df
    else:
        return None


def main():
    print("="*60)
    print("ğŸŒ¤ï¸  ASOS ê¸°ìƒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    print("="*60)
    
    # ========== ì„¤ì • ==========
    START_DATE = '2024-12-01'  # ì‹œì‘ì¼
    END_DATE = '2025-12-01'    # ì¢…ë£Œì¼
    STN_IDS = '146'            # ì „ì£¼ ê¸°ìƒëŒ€ (146)
    SERVICE_KEY = ''
    
    OUTPUT_DIR = 'input'       # ì €ì¥ í´ë”
    OUTPUT_FILE = 'asos_weather.csv'  # ì €ì¥ íŒŒì¼ëª…
    # ==========================
    
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
    
    print(f"\nğŸ“‹ ë‹¤ìš´ë¡œë“œ ì„¤ì •:")
    print(f"  â€¢ ì‹œì‘ì¼: {START_DATE}")
    print(f"  â€¢ ì¢…ë£Œì¼: {END_DATE}")
    print(f"  â€¢ ê¸°ìƒëŒ€: {STN_IDS} (ì „ì£¼)")
    print(f"  â€¢ ì €ì¥ ê²½ë¡œ: {output_path}")
    
    # ê¸°ê°„ ê³„ì‚°
    start_dt = datetime.strptime(START_DATE, '%Y-%m-%d')
    end_dt = datetime.strptime(END_DATE, '%Y-%m-%d')
    total_days = (end_dt - start_dt).days + 1
    total_hours = total_days * 24
    
    print(f"  â€¢ ê¸°ê°„: {total_days}ì¼ ({total_hours}ì‹œê°„)")
    
    # API ì—°ê²° í…ŒìŠ¤íŠ¸
    if not test_api_connection(SERVICE_KEY, STN_IDS):
        print("\nâŒ API ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    print("\n" + "="*60)
    print("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    print("="*60)
    
    # 30ì¼ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ë‹¤ìš´ë¡œë“œ (API íƒ€ì„ì•„ì›ƒ ë°©ì§€)
    asos_df = download_asos_data_by_period(
        START_DATE, 
        END_DATE, 
        STN_IDS, 
        SERVICE_KEY,
        days_per_fetch=30
    )
    
    if asos_df is None or len(asos_df) == 0:
        print("\nâŒ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    asos_df = process_asos_data(asos_df)
    
    if asos_df is None:
        print("\nâŒ ë°ì´í„° ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì €ì¥
    print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    asos_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"  âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    print("="*60)
    print(f"ğŸ“Š ë°ì´í„° ìš”ì•½:")
    print(f"  â€¢ ì´ ë ˆì½”ë“œ: {len(asos_df)}ê°œ")
    print(f"  â€¢ ê¸°ê°„: {asos_df['Date&Time'].min()} ~ {asos_df['Date&Time'].max()}")
    print(f"  â€¢ ì»¬ëŸ¼: {list(asos_df.columns)}")
    print(f"  â€¢ ì €ì¥ ê²½ë¡œ: {output_path}")
    
    # í†µê³„ ì •ë³´
    print(f"\nğŸ“ˆ ê¸°ìƒ ë°ì´í„° í†µê³„:")
    stats_cols = []
    for col in ['outer_temp', 'outer_hum', 'wind_speed', 'rainfall']:
        if col in asos_df.columns:
            stats_cols.append(col)
    
    if stats_cols:
        print(asos_df[stats_cols].describe())
    
    # ê²°ì¸¡ì¹˜ í™•ì¸
    missing = asos_df.isnull().sum()
    if missing.sum() > 0:
        print(f"\nâš ï¸  ê²°ì¸¡ì¹˜:")
        for col, count in missing[missing > 0].items():
            print(f"  â€¢ {col}: {count}ê°œ ({count/len(asos_df)*100:.1f}%)")
    else:
        print(f"\nâœ… ê²°ì¸¡ì¹˜ ì—†ìŒ")
    
    print("\n" + "="*60)
    print("="*60)


if __name__ == "__main__":

    main()
