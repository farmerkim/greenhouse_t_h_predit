import numpy as np
import pandas as pd
import pickle
import torch
import torch.nn as nn
from datetime import datetime, timedelta
import os

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class GreenhousePredictionLSTM(nn.Module):
    """
    í•™ìŠµëœ ëª¨ë¸ê³¼ ë™ì¼í•œ êµ¬ì¡°
    ê¸°ìƒì²­ ë°ì´í„° + í˜„ì¬ ì˜¨ì‹¤ ìƒíƒœ -> Nì‹œê°„ í›„ ì˜¨ì‹¤ ìƒíƒœ ì˜ˆì¸¡
    """
    def __init__(self, weather_input_size, greenhouse_input_size, 
                 hidden_size, num_layers, output_size, dropout=0.2):
        super(GreenhousePredictionLSTM, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # ê¸°ìƒ ë°ì´í„° ì²˜ë¦¬ LSTM
        self.weather_lstm = nn.LSTM(
            input_size=weather_input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        # ì˜¨ì‹¤ ë°ì´í„° ì²˜ë¦¬ ë ˆì´ì–´
        self.greenhouse_encoder = nn.Sequential(
            nn.Linear(greenhouse_input_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # í†µí•© ë ˆì´ì–´
        combined_size = hidden_size + hidden_size // 2
        self.fc = nn.Sequential(
            nn.Linear(combined_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, output_size)
        )
    
    def forward(self, weather_data, greenhouse_data):
        # ê¸°ìƒ ë°ì´í„° LSTM ì²˜ë¦¬
        lstm_out, (h_n, c_n) = self.weather_lstm(weather_data)
        weather_features = lstm_out[:, -1, :]  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…
        
        # ì˜¨ì‹¤ ë°ì´í„° ì¸ì½”ë”©
        greenhouse_features = self.greenhouse_encoder(greenhouse_data)
        
        # íŠ¹ì„± ê²°í•©
        combined = torch.cat([weather_features, greenhouse_features], dim=1)
        
        # ìµœì¢… ì˜ˆì¸¡
        output = self.fc(combined)
        return output


class GreenhouseFuturePredictor:
    """ì˜¨ì‹¤ ë¯¸ê¸°í›„ ë¯¸ë˜ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self, model_path='output/best_model.pth', 
                 scaler_dir='output/cache'):
        self.model_path = model_path
        self.scaler_dir = scaler_dir
        self.model = None
        self.scaler_weather = None
        self.scaler_greenhouse = None
        self.scaler_y = None
        self.metadata = None
        self.device = device
    
    def load_model_and_scalers(self):
        """ì €ì¥ëœ ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        print("="*60)
        print("ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ")
        print("="*60)
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        checkpoint = torch.load(self.model_path, map_location=self.device)
        config = checkpoint['config']
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = GreenhousePredictionLSTM(
            weather_input_size=config['weather_input_size'],
            greenhouse_input_size=config['greenhouse_input_size'],
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            output_size=config['output_size'],
            dropout=config['dropout']
        ).to(self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        with open(f'{self.scaler_dir}/scaler_weather.pkl', 'rb') as f:
            self.scaler_weather = pickle.load(f)
        with open(f'{self.scaler_dir}/scaler_greenhouse.pkl', 'rb') as f:
            self.scaler_greenhouse = pickle.load(f)
        with open(f'{self.scaler_dir}/scaler_y.pkl', 'rb') as f:
            self.scaler_y = pickle.load(f)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(f'{self.scaler_dir}/metadata.pkl', 'rb') as f:
            self.metadata = pickle.load(f)
        
        return True
    
    def add_time_features(self, df):
        """ì‹œê°„ íŠ¹ì„± ì¶”ê°€"""
        df = df.copy()
        if df['Date&Time'].dtype == 'object':
            df['Date&Time'] = pd.to_datetime(df['Date&Time'])
        
        df['hour'] = df['Date&Time'].dt.hour
        df['day'] = df['Date&Time'].dt.day
        df['month'] = df['Date&Time'].dt.month
        df['dayofweek'] = df['Date&Time'].dt.dayofweek
        
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)
        df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)
        
        df['season'] = df['month'].apply(lambda x: 0 if x in [12, 1, 2] else 1 if x in [3, 4, 5] else 2 if x in [6, 7, 8] else 3)
        df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
        
        return df
    
    def get_recent_greenhouse_data(self, preprocessed_path):
        """ìµœê·¼ ì˜¨ì‹¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        df = pd.read_csv(preprocessed_path)
        last_row = df.iloc[-1]
        
        greenhouse_data = {}
        for col in self.metadata['greenhouse_cols']:
            if col in last_row:
                greenhouse_data[col] = last_row[col]
            else:
                greenhouse_data[col] = 0.0
        return greenhouse_data
    
    def load_forecast_data(self, forecast_path):
        """ê¸°ìƒì²­ ì˜ˆë³´ ë°ì´í„° ë¡œë“œ"""
        df = pd.read_csv(forecast_path)
        if 'Date&Time' in df.columns:
            df['Date&Time'] = pd.to_datetime(df['Date&Time'])
        return df.sort_values('Date&Time').reset_index(drop=True)
    
    def predict(self, forecast_path, preprocessed_path, target_date=None, hours_to_predict=6):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        print("="*60)
        print(f"ì˜¨ì‹¤ ì˜¨ìŠµë„ ì˜ˆì¸¡ ì‹œì‘")
        print("="*60)
        
        if self.model is None:
            self.load_model_and_scalers()
        
        sequence_length = self.metadata['sequence_length']
        weather_cols = self.metadata['weather_cols']
        greenhouse_cols = self.metadata['greenhouse_cols']
        
        # 1. ë°ì´í„° ë¡œë“œ
        current_greenhouse = self.get_recent_greenhouse_data(preprocessed_path)
        forecast_df = self.load_forecast_data(forecast_path)
        forecast_df = self.add_time_features(forecast_df)
        
        # 2. ë‚ ì§œ í•„í„°ë§ (target_dateê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œì  ì´í›„ ë°ì´í„° ëª¨ë‘ ì‚¬ìš©)
        if target_date:
            target_dt = pd.to_datetime(target_date)
            # íƒ€ê²Ÿ ë‚ ì§œì˜ ë°ì´í„°ë¶€í„° ì‹œì‘ (ì´ì „ ë°ì´í„°ëŠ” ì‹œí€€ìŠ¤ êµ¬ì„±ì„ ìœ„í•´ í•„ìš”í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„  ê°„ë‹¨íˆ í•´ë‹¹ì¼ ì´í›„ë¡œ í•„í„°)
            forecast_data = forecast_df[forecast_df['Date&Time'] >= target_dt].copy()
        else:
            forecast_data = forecast_df.copy()
            
        forecast_data = forecast_data.sort_values('Date&Time').reset_index(drop=True)
        
        # 3. [ì¤‘ìš”] ëˆ„ë½ëœ ê¸°ìƒ ì»¬ëŸ¼ ì±„ìš°ê¸° (solar_rad, pressure ë“±)
        for col in weather_cols:
            if col not in forecast_data.columns:
                print(f"âš ï¸ ì˜ˆë³´ ë°ì´í„°ì— '{col}' ì»¬ëŸ¼ ëˆ„ë½ -> ê¸°ë³¸ê°’ ëŒ€ì²´")
                if 'solar' in col or 'rad' in col:
                    forecast_data[col] = 0.0  # ì¼ì‚¬ëŸ‰ 0
                elif 'pressure' in col:
                    forecast_data[col] = 1013.0  # í‘œì¤€ê¸°ì••
                else:
                    forecast_data[col] = 0.0
        
        # 4. ë°ì´í„° ê¸¸ì´ í™•ì¸
        if len(forecast_data) < sequence_length:
            print(f"âŒ ë°ì´í„° ë¶€ì¡±: {len(forecast_data)}ê°œ < í•„ìš” {sequence_length}ê°œ")
            return None
            
        predictions = []
        
        # 5. ì˜ˆì¸¡ ë£¨í”„
        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ íšŸìˆ˜: (ì „ì²´ ë°ì´í„° ê¸¸ì´ - ì‹œí€€ìŠ¤ ê¸¸ì´ + 1) ê³¼ (ìš”ì²­í•œ ì˜ˆì¸¡ ì‹œê°„) ì¤‘ ì‘ì€ ê°’
        max_predictions = min(hours_to_predict, len(forecast_data) - sequence_length + 1)
        
        print(f"ğŸ”„ ì´ {max_predictions}ì‹œê°„ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        
        for i in range(max_predictions):
            # ì…ë ¥ ì‹œí€€ìŠ¤ ì¶”ì¶œ
            weather_seq = forecast_data[weather_cols].iloc[i : i + sequence_length].values
            
            # í˜„ì¬ ì˜¨ì‹¤ ìƒíƒœ (ê³ ì •ê°’ ì‚¬ìš©)
            greenhouse_state = np.array([current_greenhouse[col] for col in greenhouse_cols])
            
            # ìŠ¤ì¼€ì¼ë§
            weather_seq_scaled = self.scaler_weather.transform(weather_seq)
            weather_seq_scaled = weather_seq_scaled.reshape(1, sequence_length, -1)
            
            greenhouse_state_scaled = self.scaler_greenhouse.transform(greenhouse_state.reshape(1, -1))
            
            # í…ì„œ ë³€í™˜
            weather_tensor = torch.FloatTensor(weather_seq_scaled).to(self.device)
            greenhouse_tensor = torch.FloatTensor(greenhouse_state_scaled).to(self.device)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            with torch.no_grad():
                output_scaled = self.model(weather_tensor, greenhouse_tensor)
                output = self.scaler_y.inverse_transform(output_scaled.cpu().numpy())
            
            # ê²°ê³¼ ì €ì¥
            prediction_time = forecast_data.iloc[i + sequence_length - 1]['Date&Time']
            
            pred_row = {
                'Date&Time': prediction_time,
                'Hours_Ahead': i + 1,
                'Predicted_inner_temp': output[0, 0],
                'Predicted_inner_hum': output[0, 1]
            }
            
            # ì‹œê°í™”ë¥¼ ìœ„í•´ ê¸°ìƒ ì •ë³´ë„ í•¨ê»˜ ì €ì¥
            forecast_row = forecast_data.iloc[i + sequence_length - 1]
            for c in ['outer_temp', 'outer_hum', 'wind_speed', 'rainfall']:
                if c in forecast_row:
                    pred_row[c] = forecast_row[c]
                    
            predictions.append(pred_row)
            
        if not predictions:
            print("âŒ ìƒì„±ëœ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        results_df = pd.DataFrame(predictions)
        
        # ì €ì¥
        os.makedirs('output', exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        save_path = f'output/prediction_result_{timestamp}.csv'
        results_df.to_csv(save_path, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ ë° ì €ì¥: {save_path}")
        return results_df

def main():
    # í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
    MODEL_PATH = 'output/best_model.pth'
    SCALER_DIR = 'output/cache'
    FORECAST_PATH = 'input/weather_forecast.csv'
    PREPROCESSED_PATH = 'output/preprocessed_data.csv'
    
    predictor = GreenhouseFuturePredictor(MODEL_PATH, SCALER_DIR)
    
    if os.path.exists(FORECAST_PATH) and os.path.exists(PREPROCESSED_PATH):
        try:
            results = predictor.predict(FORECAST_PATH, PREPROCESSED_PATH)
            if results is not None:
                print(results)
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
    else:
        print("í•„ìš”í•œ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    main()